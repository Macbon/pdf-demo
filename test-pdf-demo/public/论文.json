{"success_count":2,"total_count":2,"valid_page_number":2,"x_request_id":"e57a4f5e12f9d17138148eb5e424b915","metrics":[{"angle":0,"page_id":1,"dpi":144,"image_id":"b636d7c77a9b4120.jpg","page_image_width":1224,"duration":1196.1691894531,"status":"Success","page_image_height":1584},{"angle":0,"status":"Success","dpi":144,"page_id":2,"image_id":"99bf70b7b5b55e37.jpg","duration":1339.9307861328,"page_image_width":1224,"page_image_height":1584}],"detail":[{"paragraph_id":0,"page_id":1,"tags":[],"outline_level":0,"text":"DGP:A Dual-Granularity Prompting Framework for Fraud Detection with","type":"paragraph","position":[146,193,1076,196,1077,223,147,220],"content":0,"sub_type":"text_title"},{"paragraph_id":1,"page_id":1,"tags":[],"outline_level":0,"text":"Graph-Enhanced LLMs","content":0,"position":[461,228,764,228,764,255,461,255],"type":"paragraph","sub_type":"text_title"},{"paragraph_id":2,"page_id":1,"tags":[],"outline_level":-1,"text":"**Yuan Li', Jun Hu', Bryan Hooi', Bingsheng He',Cheng Chen2**","content":0,"position":[294,284,936,284,936,307,294,307],"sub_type":"text","type":"paragraph"},{"paragraph_id":3,"page_id":1,"content":0,"outline_level":-1,"text":"National University of Singapore 2ByteDance Inc.","tags":[],"position":[405,319,818,319,818,337,405,337],"sub_type":"text","type":"paragraph"},{"paragraph_id":4,"page_id":1,"tags":[],"outline_level":-1,"text":"li.yuan@u.nus.edu,{jun.hu,dcsbhk,dcsheb}@nus.edu.sg,chencheng.sg@bytedance.com","type":"paragraph","position":[249,343,975,343,975,362,249,362],"content":0,"sub_type":"text"},{"paragraph_id":5,"page_id":1,"tags":[],"outline_level":1,"text":"Abstract","type":"paragraph","position":[308,437,385,437,385,452,308,452],"content":0,"sub_type":"text_title"},{"paragraph_id":6,"page_id":1,"content":0,"outline_level":-1,"text":"Real-world fraud detection applications benefits from graph learning techniques that jointly exploit node features-often rich in textual data-and graph structural information. Re-cently,Graph-Enhanced LLMs emerge as a promising graph learning approach that converts graph information into prompts, exploiting LLMs' ability to reason over both textual and structural information. Among them, text-only prompt-ing,which converts graph information to prompts consist-ing solely of text tokens, offers a solution that relies only on LLM tuning without requiring additional graph-specific en-coders. However, text-only prompting struggles on heteroge-neous fraud-detection graphs: multi-hop relations expand ex-ponentially with each additional hop, leading to rapidly grow-ing neighborhoods associated with dense textual information. These neighborhoods may overwhelm the model with long, irrelevant content in theprompt and suppress key signals from the target node,thereby degrading performance. To ad-dress this challenge, we propose Dual Granularity Prompting (DGP),which mitigates information overload by preserving fine-grained textual details for the target node while summa-rizing neighbor information into coarse-grained text prompts. DGP introduces tailored summarization strategies for differ-ent data modalities-bi-level semantic abstraction for tex-tual fields and statistical aggregation for numerical features-enabling effective compression of verbose neighbor content into concise, informative prompts. Experiments across public and industrial datasets demonstrate that DGP operates within a manageable token budget while improving fraud detection performance by up to 6.8% (AUPRC) over state-of-the-art methods,showing the potential of Graph-Enhanced LLMs for fraud detection.","type":"paragraph","position":[124,470,568,470,568,1082,124,1082],"tags":[],"sub_type":"text"},{"paragraph_id":7,"page_id":1,"tags":[],"outline_level":1,"text":"1 Introduction","sub_type":"text_title","position":[260,1117,431,1119,432,1136,261,1135],"content":0,"type":"paragraph"},{"paragraph_id":8,"page_id":1,"content":0,"outline_level":-1,"text":"Graph-based fraud detection has emerged as a critical re-search direction, driven by its effectiveness in capturing the complex relational patterns inherent in real-world data (Xu et al. 2024; Akoglu, Tong, and Koutra 2015; Rayana and Akoglu 2015). The intricate structural properties of graphs, combined with the rich semantic and numerical information on nodes, present unique opportunities and challenges for effectively identifying fraudulent entities. Real-world appli-cations such as anomaly detection in social networks (Chen et al. 2024; Sharma et al. 2018), fake account identifica-tion (Li et al. 2022; Hooi et al. 2017), and the detection of malicious user-generated content (Rayana and Akoglu 2015;","sub_type":"text","position":[104,1148,588,1148,588,1406,104,1406],"tags":[],"type":"paragraph"},{"paragraph_id":9,"page_id":1,"content":0,"outline_level":-1,"text":"Relation Types Same User V1 [User B|1 Star] V3 [User C|1 Star] Same Product& Rating Food was cold... XYZ is better... Same Product & Month Vo [User A |2 Stars] V1 [User A|1 Star] Makes me miss XYZ.. Better options nearby..","type":"image","position":[636,428,1118,429,1118,536,635,536],"caption_id":{"paragraph_id":10,"page_id":1},"image_url":"https://web-api.textin.com/ocr_image/external/d0ca597b3399a749.jpg"},{"paragraph_id":10,"page_id":1,"content":0,"outline_level":-1,"text":"(a) Fraudsters exhibit rich semantic patterns","type":"paragraph","position":[716,553,1038,553,1038,567,716,567],"tags":[],"sub_type":"image_title"},{"paragraph_id":13,"caption_id":{"paragraph_id":14,"page_id":1},"content":0,"outline_level":-1,"text":"Nodes Encoded as Vectors Vo Target:Text of v0 Neighbor:Vectors(Short) \"Fraud\" GNN Question:Is this fraud? Early encoding (node text→single vector) incurs information loss","image_url":"https://web-api.textin.com/ocr_image/external/276ac1bf825d62c0.jpg","position":[633,585,1121,585,1120,702,632,703],"page_id":1,"type":"image"},{"paragraph_id":14,"page_id":1,"tags":[],"outline_level":-1,"text":"(b) Encoding-based prompting","type":"paragraph","position":[764,713,990,713,990,729,764,729],"content":0,"sub_type":"image_title"},{"paragraph_id":18,"caption_id":{"paragraph_id":19,"page_id":1},"content":0,"outline_level":-1,"text":"Target:Text of v0 Neighbor:concatenated texts Neighbor 1:..., Neighbor 2:... (Long) \"Fraud\" Question:Is this fraud? Long concatenated neighbor texts may dominate the prompt, potentially suppressing the target node's self information","page_id":1,"position":[634,748,1120,747,1120,860,634,862],"image_url":"https://web-api.textin.com/ocr_image/external/39cb0764cfefee7b.jpg","type":"image"},{"paragraph_id":19,"page_id":1,"content":0,"outline_level":-1,"text":"(c) Text-only prompting","tags":[],"position":[787,879,967,879,967,896,787,896],"type":"paragraph","sub_type":"image_title"},{"paragraph_id":20,"page_id":1,"tags":[],"outline_level":-1,"text":"Figure 1: Graph-to-prompt methods for fraud detection.","sub_type":"image_title","position":[651,918,1101,918,1101,937,651,937],"content":0,"type":"paragraph"},{"paragraph_id":21,"page_id":1,"content":0,"outline_level":-1,"text":"McAuley and Leskovec 2013) benefit from advanced graph learning techniques.","tags":[],"position":[636,990,1118,990,1118,1029,636,1029],"sub_type":"text","type":"paragraph"},{"paragraph_id":22,"page_id":1,"tags":[],"outline_level":-1,"text":"**Graph-Enhanced LLMs for Fraud Detection.In** recent years, various Graph Neural Networks (GNNs) have been proposed for graph-based fraud detection, achieving notable success by leveraging neighborhood information and struc-tural patterns to enhance detection accuracy (Duan et al. 2024;Li et al. 2024).More recently,graph-enhanced Large Language Models (LLMs) have emerged as a promising al-ternative for graph-based fraud detection tasks,leveraging their generalizable language capabilities and demonstrating competitive performance across a range of tasks (Tang et al. 2024a,b; Liu et al. 2024b). These approaches have shown potential in analyzing the rich semantics associated with fraudulent nodes, as well as the diverse relationships among them (as illustrated in Figure 1a), by exploiting the seman-tic nuances within the graph (Tang et al. 2024a). Notably, we distinguish these methods from LLM-enhanced GNNs such as TAPE (He et al. 2024) and FLAG(Yang et al.2025),","sub_type":"text","position":[635,1037,1118,1037,1118,1406,635,1406],"content":0,"type":"paragraph"},{"paragraph_id":12,"page_id":1,"tags":[],"outline_level":-1,"text":"SZ0Cmnr67[0T.so] IAESSIC:LOsZ:AXT","type":"paragraph","position":[29,449,73,449,73,1135,29,1135],"content":1,"sub_type":"sidebar"},{"paragraph_id":0,"page_id":2,"content":0,"outline_level":-1,"text":"DGP GraphGPT TAPE InstructGLM HiGPT (8)COHnA 80 70 0 2000 4000 # Tokens per Prompt (Yelp)","type":"image","sub_type":"chart","position":[109,105,341,105,342,269,110,270],"caption_id":{"paragraph_id":2,"page_id":2},"image_url":"https://web-api.textin.com/ocr_image/external/2467567c37382dbe.jpg"},{"paragraph_id":1,"caption_id":{"paragraph_id":2,"page_id":2},"content":0,"outline_level":-1,"text":"DGP GraphGPT TAPE InstructGLM HiGPT (8)COHnA 75 70 0 1000 2000 3000 # Tokens per Prompt (Amazon)","image_url":"https://web-api.textin.com/ocr_image/external/4b80c3c8e3be0502.jpg","sub_type":"chart","position":[353,106,585,106,586,269,353,269],"page_id":2,"type":"image"},{"paragraph_id":2,"page_id":2,"tags":[],"outline_level":-1,"text":"Figure 2: Fraud detection performance (↑) vs. token us-age per prompt (↓) across different methods and datasets. Our proposed method, DGP, achieves top performance with moderate token consumption, demonstrating a notable bal-ance between token usage and performance.","sub_type":"image_title","position":[104,286,588,286,588,391,104,391],"content":0,"type":"paragraph"},{"paragraph_id":3,"page_id":2,"tags":[],"outline_level":-1,"text":"which incorporate LLM-encoded features and rely heavily on the classification capabilities of GNNs. In this work, we focus on leveraging graph-enhanced LLMs as standalone classifiers to fully explore their potential in graph-based fraud detection.","sub_type":"text","position":[105,443,588,443,588,552,105,552],"content":0,"type":"paragraph"},{"paragraph_id":4,"page_id":2,"tags":[],"outline_level":-1,"text":"To bridge the gap between graph-structured data and LLMs,graph-enhanced LLMs transform graph data into tex-tual prompts (graph-to-prompt) to naturally integrate both graph structure and semantics into LLMs (Fatemi,Halcrow, and Perozzi 2023; Ye et al. 2024). Two major graph-to-prompt strategies, as depicted in Figure 1b and 1c,have been developed in recent literature: (1) Encoding-based prompt-ing, exemplified by approaches such as GraphGPT (Tang et al. 2024a) and HiGPT (Tang et al. 2024b), encodes nodes into compact vectors and subsequently feeds them into an LLM. These methods substantially reduce prompt length via node encoding, but suffer from early vectorization, lead-ing to **information** **loss** due to reduced semantic-level in-teractions (Li et al. 2023). In contrast, (2) text-only prompt-ing (Wang et al. 2023; Ye et al. 2024; Fatemi,Halcrow,and Perozzi 2023; Zhu et al. 2025) preserves detailed semantic interactions by concatenating neighbor texts into the prompt. However, these methods inherently suffer from excessive prompt length, leading to **distraction from crucial content** due to information overload. For example, in industrial sce-narios,each neighboring node can be associated with over 1,500 tokens, resultingin a 2-hop neighborhood with up to 2 million tokens, which poses challenges for incorporating dense textual information for fraud detection.","type":"paragraph","position":[104,555,588,555,588,1074,104,1074],"content":0,"sub_type":"text"},{"paragraph_id":5,"page_id":2,"tags":[],"outline_level":-1,"text":"In this work, we propose Dual Granularity Prompting (DGP), a novel text-only prompting framework that lever-ages the rich semantics on graphs while addressing the chal-lenge of excessive prompt length. To reduce the informa-tion loss incurred by early-stage encoding,DGP selectively preserves fine-grained text for the target node while sum-marizing neighbors retrieved from different metapaths into compact, coarse-grained texts. For textual features, we em-ploy bi-level semantic summarization to reduce the prompt length. For numerical features, we adopt precise numerical summarization to retain key insights. As illustrated in Fig-ure 2,our approach achieves an impressive balance between token usage and performance. Compared to prior state-of-the-art methods, DGP operates with a manageable prompt length while improving fraud detection performance by up to 6.8% (AUPRC), demonstrating the effectiveness of our dual-granularity design with reasonable token budgets.","content":0,"type":"paragraph","split_section_positions":[[105,1082,588,1082,588,1407,105,1407],[636,112,1118,112,1118,154,636,154]],"position":[105,1082,588,1082,588,1407,105,1407],"split_section_page_ids":[2,2],"sub_type":"text"},{"paragraph_id":7,"page_id":2,"tags":[],"outline_level":-1,"text":"The key contribution of this work is three-fold:","type":"paragraph","position":[656,158,1035,158,1035,176,656,176],"content":0,"sub_type":"text"},{"paragraph_id":8,"page_id":2,"content":0,"outline_level":-1,"text":"·We propose DGP, a novel graph prompting framework that integrates fine-grained textual details for target nodes with coarse-grained semantic summaries for their neigh-bors,thereby overcoming limitations faced by existing graph-to-prompt methods.","type":"paragraph","position":[645,191,1118,191,1118,298,645,298],"tags":[],"sub_type":"text"},{"paragraph_id":9,"page_id":2,"content":0,"outline_level":-1,"text":"·We introduce specialized summarization strategies for compressing neighborhoods associated with textual and numerical features into concise, semmantically meaningful prompts tailored for LLM processing.","sub_type":"text","position":[645,308,1118,308,1118,393,645,393],"tags":[],"type":"paragraph"},{"paragraph_id":10,"page_id":2,"tags":[],"outline_level":-1,"text":"·Extensive experiments on public and industry datasets demonstrate the superior empirical performance of DGP, achieving manageable prompt lengths while improving fraud detection performance by up to 6.8% in AUPRC compared to state-of-the-art approaches.","type":"paragraph","position":[645,404,1118,404,1118,510,645,510],"content":0,"sub_type":"text"},{"paragraph_id":11,"page_id":2,"content":0,"outline_level":1,"text":"2 Related Work","sub_type":"text_title","position":[784,539,968,539,968,557,784,557],"tags":[],"type":"paragraph"},{"paragraph_id":15,"page_id":2,"tags":[],"outline_level":2,"text":"2.1 Graph Neural Networks for Fraud Detection","type":"paragraph","position":[636,575,1108,575,1108,596,636,596],"content":0,"sub_type":"text_title"},{"paragraph_id":16,"page_id":2,"tags":[],"outline_level":-1,"text":"Graph neural networks (GNNs) have become the dominant approach for fraud detection by modeling relational pat-terns in graphs (Akoglu, Tong, and Koutra 2015; Rayana and Akoglu 2015; Duan et al. 2024; Li et al. 2024).Clas-sic models such as GCN (Kipf and Welling 2017) and GAT (Veličković et al. 2018) have inspired many variants targeting specific challenges, including camouflage (CARE-GNN (Dou et al. 2020)),heterophily (PMP (Zhuo et al. 2024)), and limited supervision (ConsisGAD (Chen et al. 2024), barely-supervised learning (Yu, Liu, and Luo 2024)). However, most GNN-based approaches underutilize the fine-grained textual semantics widely available in real-world graphs, which our method explicitly addresses.","type":"paragraph","position":[634,608,1118,608,1118,891,634,891],"content":0,"sub_type":"text"},{"paragraph_id":17,"page_id":2,"content":0,"outline_level":2,"text":"2.2 Integrating LLMs with Graphs","tags":[],"position":[636,916,982,916,982,936,636,936],"type":"paragraph","sub_type":"text_title"},{"paragraph_id":18,"page_id":2,"content":0,"outline_level":-1,"text":"Recent advances in integrating LLMs with graph data can be broadly classified into graph-enhanced LLMs and LLM-enhanced GNNs. Graph-enhanced LLMs primarily adopt graph-to-prompt strategies, which can be divided into encoding-based prompting and text-only prompting. Encoding-based prompting (Tang et al. 2024a,b) compresses graph features for LLM input, potentially resulting in se-mantic loss. Specifically, GraphGPT (Tang et al. 2024a) aligns LLMs with graph structural information via a dual-stage instruction-tuning paradigm and a graph-text align-ment projector. HiGPT (Tang et al. 2024b) extends instruc-tion tuning to heterogeneous graphs by introducing an in-context heterogeneous-graph tokenizer and heterogeneity-aware fine-tuning. In contrast, text-only prompting (Fatemi, Halcrow, and Perozzi 2023; Ye et al. 2024; Zhu et al. 2025) concatenates the texts of neighboring nodes as in-put to LLMs,which may lead to excessively long prompts and distract from crucial information. For example, Instruct-GLM (Ye et al. 2024) frames graph tasks as natural-language instructions for generative LLMs, enabling node classifica-tion on citation networks.","tags":[],"position":[635,951,1118,951,1118,1404,635,1404],"type":"paragraph","sub_type":"text"}],"markdown":"# DGP:A Dual-Granularity Prompting Framework for Fraud Detection with\n\n# Graph-Enhanced LLMs\n\n**Yuan Li', Jun Hu', Bryan Hooi', Bingsheng He',Cheng Chen2**\n\nNational University of Singapore 2ByteDance Inc.\n\nli.yuan@u.nus.edu,{jun.hu,dcsbhk,dcsheb}@nus.edu.sg,chencheng.sg@bytedance.com\n\n## Abstract\n\nReal-world fraud detection applications benefits from graph learning techniques that jointly exploit node features-often rich in textual data-and graph structural information. Re-cently,Graph-Enhanced LLMs emerge as a promising graph learning approach that converts graph information into prompts, exploiting LLMs' ability to reason over both textual and structural information. Among them, text-only prompt-ing,which converts graph information to prompts consist-ing solely of text tokens, offers a solution that relies only on LLM tuning without requiring additional graph-specific en-coders. However, text-only prompting struggles on heteroge-neous fraud-detection graphs: multi-hop relations expand ex-ponentially with each additional hop, leading to rapidly grow-ing neighborhoods associated with dense textual information. These neighborhoods may overwhelm the model with long, irrelevant content in theprompt and suppress key signals from the target node,thereby degrading performance. To ad-dress this challenge, we propose Dual Granularity Prompting (DGP),which mitigates information overload by preserving fine-grained textual details for the target node while summa-rizing neighbor information into coarse-grained text prompts. DGP introduces tailored summarization strategies for differ-ent data modalities-bi-level semantic abstraction for tex-tual fields and statistical aggregation for numerical features-enabling effective compression of verbose neighbor content into concise, informative prompts. Experiments across public and industrial datasets demonstrate that DGP operates within a manageable token budget while improving fraud detection performance by up to 6.8% (AUPRC) over state-of-the-art methods,showing the potential of Graph-Enhanced LLMs for fraud detection.\n\n## 1 Introduction\n\nGraph-based fraud detection has emerged as a critical re-search direction, driven by its effectiveness in capturing the complex relational patterns inherent in real-world data (Xu et al. 2024; Akoglu, Tong, and Koutra 2015; Rayana and Akoglu 2015). The intricate structural properties of graphs, combined with the rich semantic and numerical information on nodes, present unique opportunities and challenges for effectively identifying fraudulent entities. Real-world appli-cations such as anomaly detection in social networks (Chen et al. 2024; Sharma et al. 2018), fake account identifica-tion (Li et al. 2022; Hooi et al. 2017), and the detection of malicious user-generated content (Rayana and Akoglu 2015;\n\n<!-- Relation Types Same User V1 [User B|1 Star] V3 [User C|1 Star] Same Product& Rating Food was cold... XYZ is better... Same Product & Month Vo [User A |2 Stars] V1 [User A|1 Star] Makes me miss XYZ.. Better options nearby.. -->\n![](https://web-api.textin.com/ocr_image/external/d0ca597b3399a749.jpg)\n\n(a) Fraudsters exhibit rich semantic patterns\n\n<!-- Nodes Encoded as Vectors Vo Target:Text of v0 Neighbor:Vectors(Short) \"Fraud\" GNN Question:Is this fraud? Early encoding (node text→single vector) incurs information loss -->\n![](https://web-api.textin.com/ocr_image/external/276ac1bf825d62c0.jpg)\n\n(b) Encoding-based prompting\n\n<!-- Target:Text of v0 Neighbor:concatenated texts Neighbor 1:..., Neighbor 2:... (Long) \"Fraud\" Question:Is this fraud? Long concatenated neighbor texts may dominate the prompt, potentially suppressing the target node's self information -->\n![](https://web-api.textin.com/ocr_image/external/39cb0764cfefee7b.jpg)\n\n(c) Text-only prompting\n\nFigure 1: Graph-to-prompt methods for fraud detection.\n\nMcAuley and Leskovec 2013) benefit from advanced graph learning techniques.\n\n**Graph-Enhanced LLMs for Fraud Detection.In** recent years, various Graph Neural Networks (GNNs) have been proposed for graph-based fraud detection, achieving notable success by leveraging neighborhood information and struc-tural patterns to enhance detection accuracy (Duan et al. 2024;Li et al. 2024).More recently,graph-enhanced Large Language Models (LLMs) have emerged as a promising al-ternative for graph-based fraud detection tasks,leveraging their generalizable language capabilities and demonstrating competitive performance across a range of tasks (Tang et al. 2024a,b; Liu et al. 2024b). These approaches have shown potential in analyzing the rich semantics associated with fraudulent nodes, as well as the diverse relationships among them (as illustrated in Figure 1a), by exploiting the seman-tic nuances within the graph (Tang et al. 2024a). Notably, we distinguish these methods from LLM-enhanced GNNs such as TAPE (He et al. 2024) and FLAG(Yang et al.2025),\n\n<!-- SZ0Cmnr67[0T.so] IAESSIC:LOsZ:AXT -->\n\n<!-- DGP GraphGPT TAPE InstructGLM HiGPT (8)COHnA 80 70 0 2000 4000 # Tokens per Prompt (Yelp) -->\n![](https://web-api.textin.com/ocr_image/external/2467567c37382dbe.jpg)\n\n<!-- DGP GraphGPT TAPE InstructGLM HiGPT (8)COHnA 75 70 0 1000 2000 3000 # Tokens per Prompt (Amazon) -->\n![](https://web-api.textin.com/ocr_image/external/4b80c3c8e3be0502.jpg)\n\nFigure 2: Fraud detection performance (↑) vs. token us-age per prompt (↓) across different methods and datasets. Our proposed method, DGP, achieves top performance with moderate token consumption, demonstrating a notable bal-ance between token usage and performance.\n\nwhich incorporate LLM-encoded features and rely heavily on the classification capabilities of GNNs. In this work, we focus on leveraging graph-enhanced LLMs as standalone classifiers to fully explore their potential in graph-based fraud detection.\n\nTo bridge the gap between graph-structured data and LLMs,graph-enhanced LLMs transform graph data into tex-tual prompts (graph-to-prompt) to naturally integrate both graph structure and semantics into LLMs (Fatemi,Halcrow, and Perozzi 2023; Ye et al. 2024). Two major graph-to-prompt strategies, as depicted in Figure 1b and 1c,have been developed in recent literature: (1) Encoding-based prompt-ing, exemplified by approaches such as GraphGPT (Tang et al. 2024a) and HiGPT (Tang et al. 2024b), encodes nodes into compact vectors and subsequently feeds them into an LLM. These methods substantially reduce prompt length via node encoding, but suffer from early vectorization, lead-ing to **information** **loss** due to reduced semantic-level in-teractions (Li et al. 2023). In contrast, (2) text-only prompt-ing (Wang et al. 2023; Ye et al. 2024; Fatemi,Halcrow,and Perozzi 2023; Zhu et al. 2025) preserves detailed semantic interactions by concatenating neighbor texts into the prompt. However, these methods inherently suffer from excessive prompt length, leading to **distraction from crucial content** due to information overload. For example, in industrial sce-narios,each neighboring node can be associated with over 1,500 tokens, resultingin a 2-hop neighborhood with up to 2 million tokens, which poses challenges for incorporating dense textual information for fraud detection.\n\nIn this work, we propose Dual Granularity Prompting (DGP), a novel text-only prompting framework that lever-ages the rich semantics on graphs while addressing the chal-lenge of excessive prompt length. To reduce the informa-tion loss incurred by early-stage encoding,DGP selectively preserves fine-grained text for the target node while sum-marizing neighbors retrieved from different metapaths into compact, coarse-grained texts. For textual features, we em-ploy bi-level semantic summarization to reduce the prompt length. For numerical features, we adopt precise numerical summarization to retain key insights. As illustrated in Fig-ure 2,our approach achieves an impressive balance between token usage and performance. Compared to prior state-of-the-art methods, DGP operates with a manageable prompt length while improving fraud detection performance by up to 6.8% (AUPRC), demonstrating the effectiveness of our dual-granularity design with reasonable token budgets.\n\nThe key contribution of this work is three-fold:\n\n·We propose DGP, a novel graph prompting framework that integrates fine-grained textual details for target nodes with coarse-grained semantic summaries for their neigh-bors,thereby overcoming limitations faced by existing graph-to-prompt methods.\n\n·We introduce specialized summarization strategies for compressing neighborhoods associated with textual and numerical features into concise, semmantically meaningful prompts tailored for LLM processing.\n\n·Extensive experiments on public and industry datasets demonstrate the superior empirical performance of DGP, achieving manageable prompt lengths while improving fraud detection performance by up to 6.8% in AUPRC compared to state-of-the-art approaches.\n\n## 2 Related Work\n\n### 2.1 Graph Neural Networks for Fraud Detection\n\nGraph neural networks (GNNs) have become the dominant approach for fraud detection by modeling relational pat-terns in graphs (Akoglu, Tong, and Koutra 2015; Rayana and Akoglu 2015; Duan et al. 2024; Li et al. 2024).Clas-sic models such as GCN (Kipf and Welling 2017) and GAT (Veličković et al. 2018) have inspired many variants targeting specific challenges, including camouflage (CARE-GNN (Dou et al. 2020)),heterophily (PMP (Zhuo et al. 2024)), and limited supervision (ConsisGAD (Chen et al. 2024), barely-supervised learning (Yu, Liu, and Luo 2024)). However, most GNN-based approaches underutilize the fine-grained textual semantics widely available in real-world graphs, which our method explicitly addresses.\n\n### 2.2 Integrating LLMs with Graphs\n\nRecent advances in integrating LLMs with graph data can be broadly classified into graph-enhanced LLMs and LLM-enhanced GNNs. Graph-enhanced LLMs primarily adopt graph-to-prompt strategies, which can be divided into encoding-based prompting and text-only prompting. Encoding-based prompting (Tang et al. 2024a,b) compresses graph features for LLM input, potentially resulting in se-mantic loss. Specifically, GraphGPT (Tang et al. 2024a) aligns LLMs with graph structural information via a dual-stage instruction-tuning paradigm and a graph-text align-ment projector. HiGPT (Tang et al. 2024b) extends instruc-tion tuning to heterogeneous graphs by introducing an in-context heterogeneous-graph tokenizer and heterogeneity-aware fine-tuning. In contrast, text-only prompting (Fatemi, Halcrow, and Perozzi 2023; Ye et al. 2024; Zhu et al. 2025) concatenates the texts of neighboring nodes as in-put to LLMs,which may lead to excessively long prompts and distract from crucial information. For example, Instruct-GLM (Ye et al. 2024) frames graph tasks as natural-language instructions for generative LLMs, enabling node classifica-tion on citation networks.\n\n","pages":[{"angle":0,"page_id":1,"content":[{"angle":0,"pos":[147,192,1077,195,1077,228,147,225],"id":0,"score":0.98299998044968,"type":"line","text":"DGP:A Dual-Granularity Prompting Framework for Fraud Detection with"},{"angle":0,"pos":[461,227,764,227,764,257,461,257],"id":1,"type":"line","score":0.99199998378754,"text":"Graph-Enhanced LLMs"},{"angle":0,"pos":[294,283,936,283,936,311,294,311],"id":2,"score":0.95800000429153,"type":"line","text":"Yuan Li', Jun Hu', Bryan Hooi', Bingsheng He',Cheng Chen2"},{"angle":0,"pos":[405,317,818,317,818,343,405,343],"id":3,"score":0.97899997234344,"text":"National University of Singapore 2ByteDance Inc.","type":"line"},{"angle":0,"pos":[249,340,975,340,975,365,249,365],"id":4,"score":0.9990000128746,"type":"line","text":"li.yuan@u.nus.edu,{jun.hu,dcsbhk,dcsheb}@nus.edu.sg,chencheng.sg@bytedance.com"},{"angle":0,"pos":[308,436,385,436,385,455,308,455],"id":5,"type":"line","score":0.9990000128746,"text":"Abstract"},{"angle":0,"pos":[125,469,566,470,566,490,125,489],"id":6,"type":"line","score":0.98699998855591,"text":"Real-world fraud detection applications benefits from graph"},{"angle":0,"pos":[125,487,568,487,568,510,125,510],"id":7,"text":"learning techniques that jointly exploit node features-often","score":0.99000000953674,"type":"line"},{"angle":0,"pos":[124,507,566,507,566,531,124,531],"id":8,"score":0.98699998855591,"text":"rich in textual data-and graph structural information. Re-","type":"line"},{"angle":0,"pos":[124,527,568,527,568,551,124,551],"id":9,"type":"line","score":0.99400001764297,"text":"cently,Graph-Enhanced LLMs emerge as a promising graph"},{"angle":0,"pos":[124,548,568,548,568,571,124,571],"id":10,"type":"line","score":0.99299997091293,"text":"learning approach that converts graph information into"},{"angle":0,"pos":[124,568,568,568,568,591,124,591],"id":11,"score":0.98600000143051,"text":"prompts, exploiting LLMs' ability to reason over both textual","type":"line"},{"angle":0,"pos":[124,588,566,588,566,611,124,611],"id":12,"text":"and structural information. Among them, text-only prompt-","score":0.99000000953674,"type":"line"},{"angle":0,"pos":[124,608,566,608,566,631,124,631],"id":13,"score":0.99400001764297,"type":"line","text":"ing,which converts graph information to prompts consist-"},{"angle":0,"pos":[124,628,568,628,568,651,124,651],"id":14,"type":"line","score":0.98400002717972,"text":"ing solely of text tokens, offers a solution that relies only on"},{"angle":0,"pos":[124,648,566,648,566,671,124,671],"id":15,"score":0.99500000476837,"text":"LLM tuning without requiring additional graph-specific en-","type":"line"},{"angle":0,"pos":[124,668,566,668,566,691,124,691],"id":16,"type":"line","score":0.97299998998642,"text":"coders. However, text-only prompting struggles on heteroge-"},{"angle":0,"pos":[125,690,566,690,566,708,125,708],"id":17,"type":"line","score":0.99000000953674,"text":"neous fraud-detection graphs: multi-hop relations expand ex-"},{"angle":0,"pos":[124,708,566,708,566,732,124,732],"id":18,"score":0.97899997234344,"type":"line","text":"ponentially with each additional hop, leading to rapidly grow-"},{"angle":0,"pos":[124,727,566,727,566,750,124,750],"id":19,"type":"line","score":0.99500000476837,"text":"ing neighborhoods associated with dense textual information."},{"angle":0,"pos":[125,747,568,747,568,770,125,770],"id":20,"score":0.98900002241135,"type":"line","text":"These neighborhoods may overwhelm the model with long,"},{"angle":0,"pos":[124,767,568,767,568,790,124,790],"id":21,"type":"line","score":0.99000000953674,"text":"irrelevant content in theprompt and suppress key signals"},{"angle":0,"pos":[127,789,566,789,566,807,127,807],"id":22,"score":0.99099999666214,"type":"line","text":"from the target node,thereby degrading performance. To ad-"},{"angle":0,"pos":[127,809,566,809,566,828,127,828],"id":23,"type":"line","score":0.99000000953674,"text":"dress this challenge, we propose Dual Granularity Prompting"},{"angle":0,"pos":[125,826,568,826,568,849,125,849],"id":24,"score":0.98900002241135,"type":"line","text":"(DGP),which mitigates information overload by preserving"},{"angle":0,"pos":[127,849,565,849,565,868,127,868],"id":25,"type":"line","score":0.98699998855591,"text":"fine-grained textual details for the target node while summa-"},{"angle":0,"pos":[124,866,566,866,566,889,124,889],"id":26,"type":"line","score":0.99199998378754,"text":"rizing neighbor information into coarse-grained text prompts."},{"angle":0,"pos":[125,886,566,886,566,910,125,910],"id":27,"type":"line","score":0.99500000476837,"text":"DGP introduces tailored summarization strategies for differ-"},{"angle":0,"pos":[124,906,568,906,568,930,124,930],"id":28,"type":"line","score":0.99000000953674,"text":"ent data modalities-bi-level semantic abstraction for tex-"},{"angle":0,"pos":[124,927,568,927,568,950,124,950],"id":29,"type":"line","score":0.99400001764297,"text":"tual fields and statistical aggregation for numerical features-"},{"angle":0,"pos":[124,947,568,947,568,970,124,970],"id":30,"text":"enabling effective compression of verbose neighbor content","score":0.99299997091293,"type":"line"},{"angle":0,"pos":[124,967,568,967,568,990,124,990],"id":31,"score":0.99000000953674,"text":"into concise, informative prompts. Experiments across public","type":"line"},{"angle":0,"pos":[124,987,568,987,568,1010,124,1010],"id":32,"score":0.99099999666214,"type":"line","text":"and industrial datasets demonstrate that DGP operates within"},{"angle":0,"pos":[125,1009,566,1009,566,1027,125,1027],"id":33,"score":0.9879999756813,"type":"line","text":"a manageable token budget while improving fraud detection"},{"angle":0,"pos":[124,1026,568,1026,568,1049,124,1049],"id":34,"score":0.98600000143051,"type":"line","text":"performance by up to 6.8% (AUPRC) over state-of-the-art"},{"angle":0,"pos":[124,1046,568,1046,568,1069,124,1069],"id":35,"score":0.99699997901917,"text":"methods,showing the potential of Graph-Enhanced LLMs for","type":"line"},{"angle":0,"pos":[125,1067,241,1067,241,1086,125,1086],"id":36,"type":"line","score":0.99099999666214,"text":"fraud detection."},{"angle":0,"pos":[261,1115,432,1117,432,1142,261,1141],"id":37,"score":0.99699997901917,"text":"1 Introduction","type":"line"},{"angle":0,"pos":[105,1145,588,1145,588,1169,105,1169],"id":38,"score":0.99000000953674,"type":"line","text":"Graph-based fraud detection has emerged as a critical re-"},{"angle":0,"pos":[105,1168,588,1168,588,1191,105,1191],"id":39,"text":"search direction, driven by its effectiveness in capturing the","score":0.98500001430511,"type":"line"},{"angle":0,"pos":[105,1190,588,1188,588,1213,105,1215],"id":40,"score":0.99000000953674,"type":"line","text":"complex relational patterns inherent in real-world data (Xu"},{"angle":0,"pos":[105,1211,588,1211,588,1236,105,1236],"id":41,"score":0.97899997234344,"text":"et al. 2024; Akoglu, Tong, and Koutra 2015; Rayana and","type":"line"},{"angle":0,"pos":[105,1234,588,1234,588,1258,105,1258],"id":42,"type":"line","score":0.98699998855591,"text":"Akoglu 2015). The intricate structural properties of graphs,"},{"angle":0,"pos":[105,1255,588,1255,588,1278,105,1278],"id":43,"type":"line","score":0.99099999666214,"text":"combined with the rich semantic and numerical information"},{"angle":0,"pos":[105,1276,588,1276,588,1301,105,1301],"id":44,"score":0.98900002241135,"text":"on nodes, present unique opportunities and challenges for","type":"line"},{"angle":0,"pos":[105,1299,586,1299,586,1323,105,1323],"id":45,"score":0.99400001764297,"type":"line","text":"effectively identifying fraudulent entities. Real-world appli-"},{"angle":0,"pos":[105,1321,588,1321,588,1344,105,1344],"id":46,"score":0.98100000619888,"type":"line","text":"cations such as anomaly detection in social networks (Chen"},{"angle":0,"pos":[105,1343,588,1343,588,1366,105,1366],"id":47,"type":"line","score":0.97699999809265,"text":"et al. 2024; Sharma et al. 2018), fake account identifica-"},{"angle":0,"pos":[105,1364,588,1364,588,1388,105,1388],"id":48,"score":0.98100000619888,"type":"line","text":"tion (Li et al. 2022; Hooi et al. 2017), and the detection of"},{"angle":0,"pos":[105,1386,588,1386,588,1411,105,1411],"id":49,"score":0.99000000953674,"text":"malicious user-generated content (Rayana and Akoglu 2015;","type":"line"},{"angle":0,"pos":[661,441,735,441,735,455,661,455],"id":50,"score":0.99699997901917,"type":"line","text":"Relation Types"},{"angle":0,"pos":[661,453,716,453,716,466,661,466],"id":51,"score":0.95300000905991,"text":"Same User","type":"line"},{"angle":0,"pos":[781,447,894,447,894,464,781,464],"id":52,"score":0.91600000858307,"type":"line","text":"V1 [User B|1 Star]"},{"angle":0,"pos":[982,447,1097,447,1097,463,982,463],"id":53,"score":0.95899999141693,"type":"line","text":"V3 [User C|1 Star]"},{"angle":0,"pos":[661,464,773,464,773,478,661,478],"id":54,"score":0.96799999475479,"type":"line","text":"Same Product& Rating"},{"angle":0,"pos":[781,461,871,461,871,476,781,476],"id":55,"score":0.98100000619888,"type":"line","text":"Food was cold..."},{"angle":0,"pos":[982,461,1074,461,1074,476,982,476],"id":56,"type":"line","score":0.98500001430511,"text":"XYZ is better..."},{"angle":0,"pos":[661,476,773,476,773,490,661,490],"id":57,"score":0.9549999833107,"type":"line","text":"Same Product & Month"},{"angle":0,"pos":[741,497,865,497,865,512,741,512],"id":58,"score":0.93999999761581,"text":"Vo [User A |2 Stars]","type":"line"},{"angle":0,"pos":[968,497,1081,497,1081,512,968,512],"id":59,"score":0.93699997663498,"text":"V1 [User A|1 Star]","type":"line"},{"angle":0,"pos":[741,512,865,510,865,527,741,529],"id":60,"text":"Makes me miss XYZ..","score":0.96499997377396,"type":"line"},{"angle":0,"pos":[968,512,1101,512,1101,527,968,527],"id":61,"type":"line","score":0.98699998855591,"text":"Better options nearby.."},{"size":[481,104],"id":62,"pos":[636,428,1118,429,1118,536,635,536],"data":{"path":"https://web-api.textin.com/ocr_image/external/d0ca597b3399a749.jpg","region":[636,428,1118,429,1118,536,635,536]},"type":"image"},{"angle":0,"pos":[716,549,1038,549,1038,572,716,572],"id":63,"type":"line","score":0.97899997234344,"text":"(a) Fraudsters exhibit rich semantic patterns"},{"angle":0,"pos":[701,591,869,591,869,608,701,608],"id":64,"type":"line","score":0.99099999666214,"text":"Nodes Encoded as Vectors"},{"angle":0,"pos":[753,630,769,630,769,645,753,645],"id":65,"score":0.78799998760223,"type":"line","text":"Vo"},{"angle":0,"pos":[857,620,968,620,968,637,857,637],"id":66,"type":"line","score":0.93400001525879,"text":"Target:Text of v0"},{"angle":0,"pos":[857,634,1012,634,1012,651,857,651],"id":67,"type":"line","score":0.99500000476837,"text":"Neighbor:Vectors(Short)"},{"angle":0,"pos":[1063,634,1109,634,1109,650,1063,650],"id":68,"type":"line","score":0.97000002861023,"text":"\"Fraud\""},{"angle":0,"pos":[712,647,747,647,747,664,712,664],"id":69,"score":0.98400002717972,"type":"line","text":"GNN"},{"angle":0,"pos":[857,650,998,650,998,667,857,667],"id":70,"score":0.99199998378754,"type":"line","text":"Question:Is this fraud?"},{"angle":0,"pos":[674,678,1081,678,1081,696,674,696],"id":71,"score":0.98100000619888,"type":"line","text":"Early encoding (node text→single vector) incurs information loss"},{"size":[485,116],"id":72,"pos":[633,585,1121,585,1120,702,632,703],"data":{"path":"https://web-api.textin.com/ocr_image/external/276ac1bf825d62c0.jpg","region":[633,585,1121,585,1120,702,632,703]},"type":"image"},{"angle":0,"pos":[764,710,990,710,990,735,764,735],"id":73,"score":0.99199998378754,"type":"line","text":"(b) Encoding-based prompting"},{"angle":0,"pos":[764,758,876,758,876,775,764,775],"id":74,"type":"line","score":0.94599997997284,"text":"Target:Text of v0"},{"angle":0,"pos":[764,770,939,770,939,789,764,789],"id":75,"type":"line","score":0.99599999189377,"text":"Neighbor:concatenated texts"},{"angle":0,"pos":[778,787,987,787,987,804,778,804],"id":76,"score":0.93999999761581,"type":"line","text":"Neighbor 1:..., Neighbor 2:... (Long)"},{"angle":0,"pos":[1063,787,1111,787,1111,804,1063,804],"id":77,"type":"line","score":0.98000001907349,"text":"\"Fraud\""},{"angle":0,"pos":[764,803,906,803,906,820,764,820],"id":78,"type":"line","score":0.99400001764297,"text":"Question:Is this fraud?"},{"angle":0,"pos":[690,826,1064,826,1064,845,690,845],"id":79,"text":"Long concatenated neighbor texts may dominate the prompt,","score":0.98500001430511,"type":"line"},{"angle":0,"pos":[699,843,1055,841,1055,860,699,862],"id":80,"text":"potentially suppressing the target node's self information","score":0.99000000953674,"type":"line"},{"pos":[634,748,1120,747,1120,860,634,862],"id":81,"size":[483,110],"data":{"region":[634,748,1120,747,1120,860,634,862],"path":"https://web-api.textin.com/ocr_image/external/39cb0764cfefee7b.jpg"},"type":"image"},{"angle":0,"pos":[787,876,967,876,967,899,787,899],"id":82,"type":"line","score":0.98000001907349,"text":"(c) Text-only prompting"},{"angle":0,"pos":[651,916,1101,916,1101,941,651,941],"id":83,"score":0.98900002241135,"text":"Figure 1: Graph-to-prompt methods for fraud detection.","type":"line"},{"angle":0,"pos":[636,988,1118,988,1118,1013,636,1013],"id":84,"text":"McAuley and Leskovec 2013) benefit from advanced graph","score":0.98299998044968,"type":"line"},{"angle":0,"pos":[636,1010,801,1010,801,1035,636,1035],"id":85,"text":"learning techniques.","score":0.9879999756813,"type":"line"},{"angle":0,"pos":[656,1035,1118,1035,1118,1060,656,1060],"id":86,"score":0.98900002241135,"text":"Graph-Enhanced LLMs for Fraud Detection.In recent","type":"line"},{"angle":0,"pos":[636,1058,1118,1058,1118,1083,636,1083],"id":87,"score":0.98199999332428,"text":"years, various Graph Neural Networks (GNNs) have been","type":"line"},{"angle":0,"pos":[636,1080,1118,1080,1118,1104,636,1104],"id":88,"score":0.98699998855591,"type":"line","text":"proposed for graph-based fraud detection, achieving notable"},{"angle":0,"pos":[636,1103,1118,1101,1118,1125,636,1127],"id":89,"score":0.99099999666214,"type":"line","text":"success by leveraging neighborhood information and struc-"},{"angle":0,"pos":[636,1125,1118,1125,1118,1148,636,1148],"id":90,"type":"line","score":0.99099999666214,"text":"tural patterns to enhance detection accuracy (Duan et al."},{"angle":0,"pos":[636,1145,1118,1145,1118,1169,636,1169],"id":91,"score":0.98299998044968,"text":"2024;Li et al. 2024).More recently,graph-enhanced Large","type":"line"},{"angle":0,"pos":[636,1168,1118,1168,1118,1191,636,1191],"id":92,"score":0.98900002241135,"text":"Language Models (LLMs) have emerged as a promising al-","type":"line"},{"angle":0,"pos":[636,1190,1118,1190,1118,1214,636,1214],"id":93,"type":"line","score":0.99500000476837,"text":"ternative for graph-based fraud detection tasks,leveraging"},{"angle":0,"pos":[636,1211,1118,1211,1118,1236,636,1236],"id":94,"score":0.99500000476837,"text":"their generalizable language capabilities and demonstrating","type":"line"},{"angle":0,"pos":[636,1234,1118,1234,1118,1258,636,1258],"id":95,"type":"line","score":0.99199998378754,"text":"competitive performance across a range of tasks (Tang et al."},{"angle":0,"pos":[636,1255,1118,1255,1118,1278,636,1278],"id":96,"score":0.98900002241135,"type":"line","text":"2024a,b; Liu et al. 2024b). These approaches have shown"},{"angle":0,"pos":[636,1276,1118,1276,1118,1301,636,1301],"id":97,"score":0.99400001764297,"type":"line","text":"potential in analyzing the rich semantics associated with"},{"angle":0,"pos":[636,1299,1118,1299,1118,1323,636,1323],"id":98,"type":"line","score":0.98900002241135,"text":"fraudulent nodes, as well as the diverse relationships among"},{"angle":0,"pos":[636,1321,1118,1321,1118,1344,636,1344],"id":99,"score":0.97100001573563,"type":"line","text":"them (as illustrated in Figure 1a), by exploiting the seman-"},{"angle":0,"pos":[636,1343,1118,1343,1118,1367,636,1367],"id":100,"score":0.97500002384186,"type":"line","text":"tic nuances within the graph (Tang et al. 2024a). Notably,"},{"angle":0,"pos":[636,1364,1118,1364,1118,1389,636,1389],"id":101,"type":"line","score":0.99599999189377,"text":"we distinguish these methods from LLM-enhanced GNNs"},{"angle":0,"pos":[636,1386,1118,1386,1118,1411,636,1411],"id":102,"type":"line","score":0.98400002717972,"text":"such as TAPE (He et al. 2024) and FLAG(Yang et al.2025),"},{"angle":0,"pos":[29,449,73,449,73,1135,29,1135],"id":103,"type":"line","score":0.67400002479553,"text":"SZ0Cmnr67[0T.so] IAESSIC:LOsZ:AXT"}],"status":"Success","height":1584,"structured":[{"pos":[146,193,1076,196,1077,223,147,220],"type":"textblock","id":0,"content":[0],"sub_type":"text_title","outline_level":0,"text":"DGP:A Dual-Granularity Prompting Framework for Fraud Detection with"},{"pos":[461,228,764,228,764,255,461,255],"sub_type":"text_title","id":1,"content":[1],"type":"textblock","outline_level":0,"text":"Graph-Enhanced LLMs"},{"pos":[294,284,936,284,936,307,294,307],"text":"Yuan Li', Jun Hu', Bryan Hooi', Bingsheng He',Cheng Chen2","id":2,"content":[2],"sub_type":"text","outline_level":-1,"type":"textblock"},{"pos":[405,319,818,319,818,337,405,337],"type":"textblock","id":3,"content":[3],"sub_type":"text","outline_level":-1,"text":"National University of Singapore 2ByteDance Inc."},{"pos":[249,343,975,343,975,362,249,362],"sub_type":"text","id":4,"content":[4],"type":"textblock","outline_level":-1,"text":"li.yuan@u.nus.edu,{jun.hu,dcsbhk,dcsheb}@nus.edu.sg,chencheng.sg@bytedance.com"},{"pos":[308,437,385,437,385,452,308,452],"text":"Abstract","id":5,"content":[5],"sub_type":"text_title","outline_level":1,"type":"textblock"},{"pos":[124,470,568,470,568,1082,124,1082],"sub_type":"text","id":6,"content":[6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36],"type":"textblock","outline_level":-1,"text":"Real-world fraud detection applications benefits from graph learning techniques that jointly exploit node features-often rich in textual data-and graph structural information. Re-cently,Graph-Enhanced LLMs emerge as a promising graph learning approach that converts graph information into prompts, exploiting LLMs' ability to reason over both textual and structural information. Among them, text-only prompt-ing,which converts graph information to prompts consist-ing solely of text tokens, offers a solution that relies only on LLM tuning without requiring additional graph-specific en-coders. However, text-only prompting struggles on heteroge-neous fraud-detection graphs: multi-hop relations expand ex-ponentially with each additional hop, leading to rapidly grow-ing neighborhoods associated with dense textual information. These neighborhoods may overwhelm the model with long, irrelevant content in theprompt and suppress key signals from the target node,thereby degrading performance. To ad-dress this challenge, we propose Dual Granularity Prompting (DGP),which mitigates information overload by preserving fine-grained textual details for the target node while summa-rizing neighbor information into coarse-grained text prompts. DGP introduces tailored summarization strategies for differ-ent data modalities-bi-level semantic abstraction for tex-tual fields and statistical aggregation for numerical features-enabling effective compression of verbose neighbor content into concise, informative prompts. Experiments across public and industrial datasets demonstrate that DGP operates within a manageable token budget while improving fraud detection performance by up to 6.8% (AUPRC) over state-of-the-art methods,showing the potential of Graph-Enhanced LLMs for fraud detection."},{"pos":[260,1117,431,1119,432,1136,261,1135],"text":"1 Introduction","id":7,"content":[37],"sub_type":"text_title","outline_level":1,"type":"textblock"},{"pos":[104,1148,588,1148,588,1406,104,1406],"type":"textblock","id":8,"content":[38,39,40,41,42,43,44,45,46,47,48,49],"sub_type":"text","outline_level":-1,"text":"Graph-based fraud detection has emerged as a critical re-search direction, driven by its effectiveness in capturing the complex relational patterns inherent in real-world data (Xu et al. 2024; Akoglu, Tong, and Koutra 2015; Rayana and Akoglu 2015). The intricate structural properties of graphs, combined with the rich semantic and numerical information on nodes, present unique opportunities and challenges for effectively identifying fraudulent entities. Real-world appli-cations such as anomaly detection in social networks (Chen et al. 2024; Sharma et al. 2018), fake account identifica-tion (Li et al. 2022; Hooi et al. 2017), and the detection of malicious user-generated content (Rayana and Akoglu 2015;"},{"id":9,"pos":[636,428,1118,429,1118,536,635,536],"type":"image","caption_id":{"paragraph_id":10,"page_id":1},"content":[62],"image_url":"https://web-api.textin.com/ocr_image/external/d0ca597b3399a749.jpg","lines":[50,51,52,53,54,55,56,57,58,59,60,61],"text":"Relation Types Same User V1 [User B|1 Star] V3 [User C|1 Star] Same Product& Rating Food was cold... XYZ is better... Same Product & Month Vo [User A |2 Stars] V1 [User A|1 Star] Makes me miss XYZ.. Better options nearby.."},{"pos":[716,553,1038,553,1038,567,716,567],"type":"textblock","id":10,"content":[63],"text":"(a) Fraudsters exhibit rich semantic patterns","outline_level":-1,"sub_type":"image_title"},{"type":"image","pos":[633,585,1121,585,1120,702,632,703],"image_url":"https://web-api.textin.com/ocr_image/external/276ac1bf825d62c0.jpg","caption_id":{"paragraph_id":14,"page_id":1},"content":[72],"id":13,"lines":[64,65,66,67,68,69,70,71],"text":"Nodes Encoded as Vectors Vo Target:Text of v0 Neighbor:Vectors(Short) \"Fraud\" GNN Question:Is this fraud? Early encoding (node text→single vector) incurs information loss"},{"pos":[764,713,990,713,990,729,764,729],"type":"textblock","id":14,"content":[73],"text":"(b) Encoding-based prompting","outline_level":-1,"sub_type":"image_title"},{"image_url":"https://web-api.textin.com/ocr_image/external/39cb0764cfefee7b.jpg","pos":[634,748,1120,747,1120,860,634,862],"id":18,"caption_id":{"paragraph_id":19,"page_id":1},"content":[81],"text":"Target:Text of v0 Neighbor:concatenated texts Neighbor 1:..., Neighbor 2:... (Long) \"Fraud\" Question:Is this fraud? Long concatenated neighbor texts may dominate the prompt, potentially suppressing the target node's self information","lines":[74,75,76,77,78,79,80],"type":"image"},{"pos":[787,879,967,879,967,896,787,896],"text":"(c) Text-only prompting","id":19,"content":[82],"sub_type":"image_title","outline_level":-1,"type":"textblock"},{"pos":[651,918,1101,918,1101,937,651,937],"type":"textblock","id":20,"content":[83],"text":"Figure 1: Graph-to-prompt methods for fraud detection.","outline_level":-1,"sub_type":"image_title"},{"pos":[636,990,1118,990,1118,1029,636,1029],"type":"textblock","id":21,"content":[84,85],"text":"McAuley and Leskovec 2013) benefit from advanced graph learning techniques.","outline_level":-1,"sub_type":"text"},{"pos":[635,1037,1118,1037,1118,1406,635,1406],"type":"textblock","id":22,"content":[86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102],"text":"Graph-Enhanced LLMs for Fraud Detection.In recent years, various Graph Neural Networks (GNNs) have been proposed for graph-based fraud detection, achieving notable success by leveraging neighborhood information and struc-tural patterns to enhance detection accuracy (Duan et al. 2024;Li et al. 2024).More recently,graph-enhanced Large Language Models (LLMs) have emerged as a promising al-ternative for graph-based fraud detection tasks,leveraging their generalizable language capabilities and demonstrating competitive performance across a range of tasks (Tang et al. 2024a,b; Liu et al. 2024b). These approaches have shown potential in analyzing the rich semantics associated with fraudulent nodes, as well as the diverse relationships among them (as illustrated in Figure 1a), by exploiting the seman-tic nuances within the graph (Tang et al. 2024a). Notably, we distinguish these methods from LLM-enhanced GNNs such as TAPE (He et al. 2024) and FLAG(Yang et al.2025),","outline_level":-1,"sub_type":"text"},{"pos":[29,449,73,449,73,1135,29,1135],"blocks":[{"pos":[29,449,73,449,73,1135,29,1135],"sub_type":"text","id":12,"content":[103],"text":"SZ0Cmnr67[0T.so] IAESSIC:LOsZ:AXT","outline_level":-1,"type":"textblock"}],"type":"sidebar"}],"durations":1162.9489746094,"image_id":"b636d7c77a9b4120.jpg","width":1224},{"structured":[{"type":"image","pos":[109,105,341,105,342,269,110,270],"image_url":"https://web-api.textin.com/ocr_image/external/2467567c37382dbe.jpg","caption_id":{"paragraph_id":2,"page_id":2},"content":[12],"id":0,"lines":[0,1,2,3,4,5,6,7,8,9,10,11],"text":"DGP GraphGPT TAPE InstructGLM HiGPT (8)COHnA 80 70 0 2000 4000 # Tokens per Prompt (Yelp)"},{"image_url":"https://web-api.textin.com/ocr_image/external/4b80c3c8e3be0502.jpg","pos":[353,106,585,106,586,269,353,269],"id":1,"caption_id":{"paragraph_id":2,"page_id":2},"content":[26],"text":"DGP GraphGPT TAPE InstructGLM HiGPT (8)COHnA 75 70 0 1000 2000 3000 # Tokens per Prompt (Amazon)","lines":[13,14,15,16,17,18,19,20,21,22,23,24,25],"type":"image"},{"pos":[104,286,588,286,588,391,104,391],"text":"Figure 2: Fraud detection performance (↑) vs. token us-age per prompt (↓) across different methods and datasets. Our proposed method, DGP, achieves top performance with moderate token consumption, demonstrating a notable bal-ance between token usage and performance.","id":2,"content":[27,28,29,30,31],"sub_type":"image_title","outline_level":-1,"type":"textblock"},{"pos":[105,443,588,443,588,552,105,552],"sub_type":"text","id":3,"content":[32,33,34,35,36],"text":"which incorporate LLM-encoded features and rely heavily on the classification capabilities of GNNs. In this work, we focus on leveraging graph-enhanced LLMs as standalone classifiers to fully explore their potential in graph-based fraud detection.","outline_level":-1,"type":"textblock"},{"pos":[104,555,588,555,588,1074,104,1074],"text":"To bridge the gap between graph-structured data and LLMs,graph-enhanced LLMs transform graph data into tex-tual prompts (graph-to-prompt) to naturally integrate both graph structure and semantics into LLMs (Fatemi,Halcrow, and Perozzi 2023; Ye et al. 2024). Two major graph-to-prompt strategies, as depicted in Figure 1b and 1c,have been developed in recent literature: (1) Encoding-based prompt-ing, exemplified by approaches such as GraphGPT (Tang et al. 2024a) and HiGPT (Tang et al. 2024b), encodes nodes into compact vectors and subsequently feeds them into an LLM. These methods substantially reduce prompt length via node encoding, but suffer from early vectorization, lead-ing to information loss due to reduced semantic-level in-teractions (Li et al. 2023). In contrast, (2) text-only prompt-ing (Wang et al. 2023; Ye et al. 2024; Fatemi,Halcrow,and Perozzi 2023; Zhu et al. 2025) preserves detailed semantic interactions by concatenating neighbor texts into the prompt. However, these methods inherently suffer from excessive prompt length, leading to distraction from crucial content due to information overload. For example, in industrial sce-narios,each neighboring node can be associated with over 1,500 tokens, resultingin a 2-hop neighborhood with up to 2 million tokens, which poses challenges for incorporating dense textual information for fraud detection.","id":4,"content":[37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60],"sub_type":"text","outline_level":-1,"type":"textblock"},{"next_para_id":6,"id":5,"content":[61,62,63,64,65,66,67,68,69,70,71,72,73,74,75],"outline_level":-1,"text":"In this work, we propose Dual Granularity Prompting (DGP), a novel text-only prompting framework that lever-ages the rich semantics on graphs while addressing the chal-lenge of excessive prompt length. To reduce the informa-tion loss incurred by early-stage encoding,DGP selectively preserves fine-grained text for the target node while sum-marizing neighbors retrieved from different metapaths into compact, coarse-grained texts. For textual features, we em-ploy bi-level semantic summarization to reduce the prompt length. For numerical features, we adopt precise numerical summarization to retain key insights. As illustrated in Fig-ure 2,our approach achieves an impressive balance between token usage and performance. Compared to prior state-of-the-art methods, DGP operates with a manageable prompt length while improving fraud detection performance by up","pos":[105,1082,588,1082,588,1407,105,1407],"continue":true,"next_page_id":2,"sub_type":"text","type":"textblock"},{"pos":[636,112,1118,112,1118,154,636,154],"type":"textblock","id":6,"content":[76,77],"text":"to 6.8% (AUPRC), demonstrating the effectiveness of our dual-granularity design with reasonable token budgets.","outline_level":-1,"sub_type":"text"},{"pos":[656,158,1035,158,1035,176,656,176],"type":"textblock","id":7,"content":[78],"text":"The key contribution of this work is three-fold:","outline_level":-1,"sub_type":"text"},{"pos":[645,191,1118,191,1118,298,645,298],"text":"·We propose DGP, a novel graph prompting framework that integrates fine-grained textual details for target nodes with coarse-grained semantic summaries for their neigh-bors,thereby overcoming limitations faced by existing graph-to-prompt methods.","id":8,"content":[79,80,81,82,83],"sub_type":"text","outline_level":-1,"type":"textblock"},{"pos":[645,308,1118,308,1118,393,645,393],"type":"textblock","id":9,"content":[84,85,86,87],"sub_type":"text","outline_level":-1,"text":"·We introduce specialized summarization strategies for compressing neighborhoods associated with textual and numerical features into concise, semmantically meaningful prompts tailored for LLM processing."},{"pos":[645,404,1118,404,1118,510,645,510],"type":"textblock","id":10,"content":[88,89,90,91,92],"sub_type":"text","outline_level":-1,"text":"·Extensive experiments on public and industry datasets demonstrate the superior empirical performance of DGP, achieving manageable prompt lengths while improving fraud detection performance by up to 6.8% in AUPRC compared to state-of-the-art approaches."},{"pos":[784,539,968,539,968,557,784,557],"type":"textblock","id":11,"content":[93],"sub_type":"text_title","outline_level":1,"text":"2 Related Work"},{"pos":[636,575,1108,575,1108,596,636,596],"type":"textblock","id":15,"content":[94],"text":"2.1 Graph Neural Networks for Fraud Detection","outline_level":2,"sub_type":"text_title"},{"pos":[634,608,1118,608,1118,891,634,891],"type":"textblock","id":16,"content":[95,96,97,98,99,100,101,102,103,104,105,106,107],"text":"Graph neural networks (GNNs) have become the dominant approach for fraud detection by modeling relational pat-terns in graphs (Akoglu, Tong, and Koutra 2015; Rayana and Akoglu 2015; Duan et al. 2024; Li et al. 2024).Clas-sic models such as GCN (Kipf and Welling 2017) and GAT (Veličković et al. 2018) have inspired many variants targeting specific challenges, including camouflage (CARE-GNN (Dou et al. 2020)),heterophily (PMP (Zhuo et al. 2024)), and limited supervision (ConsisGAD (Chen et al. 2024), barely-supervised learning (Yu, Liu, and Luo 2024)). However, most GNN-based approaches underutilize the fine-grained textual semantics widely available in real-world graphs, which our method explicitly addresses.","outline_level":-1,"sub_type":"text"},{"pos":[636,916,982,916,982,936,636,936],"type":"textblock","id":17,"content":[108],"text":"2.2 Integrating LLMs with Graphs","outline_level":2,"sub_type":"text_title"},{"pos":[635,951,1118,951,1118,1404,635,1404],"type":"textblock","id":18,"content":[109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129],"text":"Recent advances in integrating LLMs with graph data can be broadly classified into graph-enhanced LLMs and LLM-enhanced GNNs. Graph-enhanced LLMs primarily adopt graph-to-prompt strategies, which can be divided into encoding-based prompting and text-only prompting. Encoding-based prompting (Tang et al. 2024a,b) compresses graph features for LLM input, potentially resulting in se-mantic loss. Specifically, GraphGPT (Tang et al. 2024a) aligns LLMs with graph structural information via a dual-stage instruction-tuning paradigm and a graph-text align-ment projector. HiGPT (Tang et al. 2024b) extends instruc-tion tuning to heterogeneous graphs by introducing an in-context heterogeneous-graph tokenizer and heterogeneity-aware fine-tuning. In contrast, text-only prompting (Fatemi, Halcrow, and Perozzi 2023; Ye et al. 2024; Zhu et al. 2025) concatenates the texts of neighboring nodes as in-put to LLMs,which may lead to excessively long prompts and distract from crucial information. For example, Instruct-GLM (Ye et al. 2024) frames graph tasks as natural-language instructions for generative LLMs, enabling node classifica-tion on citation networks.","outline_level":-1,"sub_type":"text"}],"page_id":2,"content":[{"angle":0,"pos":[131,110,162,110,162,124,131,124],"id":0,"type":"line","score":0.9990000128746,"text":"DGP"},{"angle":0,"pos":[226,110,286,110,286,125,226,125],"id":1,"type":"line","score":0.9990000128746,"text":"GraphGPT"},{"angle":0,"pos":[306,110,339,110,339,124,306,124],"id":2,"score":0.9990000128746,"type":"line","text":"TAPE"},{"angle":0,"pos":[135,127,204,127,204,141,135,141],"id":3,"score":0.99800002574921,"text":"InstructGLM","type":"line"},{"angle":0,"pos":[226,127,263,127,263,141,226,141],"id":4,"type":"line","score":0.99800002574921,"text":"HiGPT"},{"angle":0,"pos":[113,156,128,156,128,223,113,223],"id":5,"score":0.60399997234344,"type":"line","text":"(8)COHnA"},{"angle":0,"pos":[128,170,147,170,147,184,128,184],"id":6,"text":"80","score":0.99599999189377,"type":"line"},{"angle":0,"pos":[128,209,147,209,147,223,128,223],"id":7,"score":0.9990000128746,"type":"line","text":"70"},{"angle":0,"pos":[149,237,161,237,161,251,149,251],"id":8,"score":0.98299998044968,"type":"line","text":"0"},{"angle":0,"pos":[204,237,235,237,235,251,204,251],"id":9,"score":0.9990000128746,"text":"2000","type":"line"},{"angle":0,"pos":[268,237,300,237,300,251,268,251],"id":10,"score":0.9990000128746,"text":"4000","type":"line"},{"angle":0,"pos":[167,252,319,252,319,268,167,268],"id":11,"text":"# Tokens per Prompt (Yelp)","score":0.97699999809265,"type":"line"},{"pos":[109,105,341,105,342,269,110,270],"type":"image","id":12,"size":[228,161],"data":{"region":[109,105,341,105,342,269,110,270],"path":"https://web-api.textin.com/ocr_image/external/2467567c37382dbe.jpg"},"sub_type":"chart"},{"angle":0,"pos":[377,110,405,110,405,124,377,124],"id":13,"score":0.9990000128746,"type":"line","text":"DGP"},{"angle":0,"pos":[469,110,531,110,531,125,469,125],"id":14,"type":"line","score":0.9990000128746,"text":"GraphGPT"},{"angle":0,"pos":[549,110,582,110,582,125,549,125],"id":15,"score":0.9990000128746,"text":"TAPE","type":"line"},{"angle":0,"pos":[377,127,449,127,449,141,377,141],"id":16,"type":"line","score":0.99800002574921,"text":"InstructGLM"},{"angle":0,"pos":[469,125,506,125,506,141,469,141],"id":17,"text":"HiGPT","score":0.99500000476837,"type":"line"},{"angle":0,"pos":[356,156,371,156,371,223,356,223],"id":18,"type":"line","score":0.61199998855591,"text":"(8)COHnA"},{"angle":0,"pos":[373,172,390,172,390,186,373,186],"id":19,"score":0.99800002574921,"type":"line","text":"75"},{"angle":0,"pos":[373,224,390,224,390,238,373,238],"id":20,"score":0.99400001764297,"text":"70","type":"line"},{"angle":0,"pos":[391,237,404,237,404,251,391,251],"id":21,"score":0.96899998188019,"type":"line","text":"0"},{"angle":0,"pos":[430,237,463,237,463,251,430,251],"id":22,"score":0.99599999189377,"type":"line","text":"1000"},{"angle":0,"pos":[478,235,510,235,510,251,478,251],"id":23,"type":"line","score":0.99800002574921,"text":"2000"},{"angle":0,"pos":[526,237,558,237,558,251,526,251],"id":24,"type":"line","score":0.9990000128746,"text":"3000"},{"angle":0,"pos":[399,252,574,252,574,268,399,268],"id":25,"score":0.97500002384186,"type":"line","text":"# Tokens per Prompt (Amazon)"},{"pos":[353,106,585,106,586,269,353,269],"type":"image","id":26,"size":[230,161],"data":{"path":"https://web-api.textin.com/ocr_image/external/4b80c3c8e3be0502.jpg","region":[353,106,585,106,586,269,353,269]},"sub_type":"chart"},{"angle":0,"pos":[105,283,586,283,586,308,105,308],"id":27,"score":0.97399997711182,"type":"line","text":"Figure 2: Fraud detection performance (↑) vs. token us-"},{"angle":0,"pos":[105,307,586,305,586,329,105,331],"id":28,"type":"line","score":0.9879999756813,"text":"age per prompt (↓) across different methods and datasets."},{"angle":0,"pos":[105,328,588,328,588,353,105,353],"id":29,"score":0.98400002717972,"text":"Our proposed method, DGP, achieves top performance with","type":"line"},{"angle":0,"pos":[105,351,586,349,586,373,105,375],"id":30,"score":0.99500000476837,"text":"moderate token consumption, demonstrating a notable bal-","type":"line"},{"angle":0,"pos":[105,373,461,373,461,396,105,396],"id":31,"text":"ance between token usage and performance.","score":0.99099999666214,"type":"line"},{"angle":0,"pos":[105,441,588,441,588,464,105,464],"id":32,"score":0.99599999189377,"text":"which incorporate LLM-encoded features and rely heavily","type":"line"},{"angle":0,"pos":[105,463,588,463,588,486,105,486],"id":33,"text":"on the classification capabilities of GNNs. In this work, we","score":0.98500001430511,"type":"line"},{"angle":0,"pos":[105,484,588,484,588,509,105,509],"id":34,"score":0.9879999756813,"type":"line","text":"focus on leveraging graph-enhanced LLMs as standalone"},{"angle":0,"pos":[105,507,588,507,588,531,105,531],"id":35,"type":"line","score":0.98600000143051,"text":"classifiers to fully explore their potential in graph-based"},{"angle":0,"pos":[105,529,235,529,235,552,105,552],"id":36,"type":"line","score":0.98699998855591,"text":"fraud detection."},{"angle":0,"pos":[125,554,588,554,588,577,125,577],"id":37,"score":0.99000000953674,"text":"To bridge the gap between graph-structured data and","type":"line"},{"angle":0,"pos":[105,574,588,574,588,597,105,597],"id":38,"score":0.98600000143051,"text":"LLMs,graph-enhanced LLMs transform graph data into tex-","type":"line"},{"angle":0,"pos":[105,596,588,596,588,620,105,620],"id":39,"type":"line","score":0.98900002241135,"text":"tual prompts (graph-to-prompt) to naturally integrate both"},{"angle":0,"pos":[105,617,588,617,588,642,105,642],"id":40,"text":"graph structure and semantics into LLMs (Fatemi,Halcrow,","score":0.99099999666214,"type":"line"},{"angle":0,"pos":[105,639,586,639,586,664,105,664],"id":41,"type":"line","score":0.97899997234344,"text":"and Perozzi 2023; Ye et al. 2024). Two major graph-to-"},{"angle":0,"pos":[105,662,588,661,588,685,105,687],"id":42,"score":0.99099999666214,"type":"line","text":"prompt strategies, as depicted in Figure 1b and 1c,have been"},{"angle":0,"pos":[105,684,586,684,586,708,105,708],"id":43,"text":"developed in recent literature: (1) Encoding-based prompt-","score":0.98600000143051,"type":"line"},{"angle":0,"pos":[105,705,588,705,588,730,105,730],"id":44,"type":"line","score":0.97699999809265,"text":"ing, exemplified by approaches such as GraphGPT (Tang"},{"angle":0,"pos":[105,727,588,727,588,752,105,752],"id":45,"score":0.98199999332428,"type":"line","text":"et al. 2024a) and HiGPT (Tang et al. 2024b), encodes nodes"},{"angle":0,"pos":[105,750,588,750,588,773,105,773],"id":46,"text":"into compact vectors and subsequently feeds them into an","score":0.9879999756813,"type":"line"},{"angle":0,"pos":[105,772,588,772,588,797,105,797],"id":47,"score":0.98900002241135,"type":"line","text":"LLM. These methods substantially reduce prompt length"},{"angle":0,"pos":[105,794,586,794,586,817,105,817],"id":48,"text":"via node encoding, but suffer from early vectorization, lead-","score":0.98400002717972,"type":"line"},{"angle":0,"pos":[105,815,586,815,586,840,105,840],"id":49,"score":0.99099999666214,"text":"ing to information loss due to reduced semantic-level in-","type":"line"},{"angle":0,"pos":[105,837,586,837,586,862,105,862],"id":50,"score":0.9879999756813,"type":"line","text":"teractions (Li et al. 2023). In contrast, (2) text-only prompt-"},{"angle":0,"pos":[105,859,588,859,588,883,105,883],"id":51,"score":0.97600001096725,"text":"ing (Wang et al. 2023; Ye et al. 2024; Fatemi,Halcrow,and","type":"line"},{"angle":0,"pos":[105,880,588,880,588,905,105,905],"id":52,"type":"line","score":0.98699998855591,"text":"Perozzi 2023; Zhu et al. 2025) preserves detailed semantic"},{"angle":0,"pos":[105,903,586,903,586,927,105,927],"id":53,"type":"line","score":0.99400001764297,"text":"interactions by concatenating neighbor texts into the prompt."},{"angle":0,"pos":[105,925,588,925,588,948,105,948],"id":54,"score":0.98600000143051,"text":"However, these methods inherently suffer from excessive","type":"line"},{"angle":0,"pos":[105,947,588,945,588,970,105,972],"id":55,"score":0.99400001764297,"text":"prompt length, leading to distraction from crucial content","type":"line"},{"angle":0,"pos":[105,968,588,968,588,993,105,993],"id":56,"score":0.9879999756813,"type":"line","text":"due to information overload. For example, in industrial sce-"},{"angle":0,"pos":[105,990,588,990,588,1015,105,1015],"id":57,"score":0.99099999666214,"text":"narios,each neighboring node can be associated with over","type":"line"},{"angle":0,"pos":[107,1012,588,1012,588,1036,107,1036],"id":58,"score":0.98600000143051,"type":"line","text":"1,500 tokens, resultingin a 2-hop neighborhood with up to"},{"angle":0,"pos":[105,1035,588,1035,588,1060,105,1060],"id":59,"score":0.98699998855591,"text":"2 million tokens, which poses challenges for incorporating","type":"line"},{"angle":0,"pos":[105,1057,472,1057,472,1080,105,1080],"id":60,"type":"line","score":0.98500001430511,"text":"dense textual information for fraud detection."},{"angle":0,"pos":[124,1080,588,1080,588,1104,124,1104],"id":61,"type":"line","score":0.99400001764297,"text":"In this work, we propose Dual Granularity Prompting"},{"angle":0,"pos":[105,1101,588,1101,588,1126,105,1126],"id":62,"type":"line","score":0.98600000143051,"text":"(DGP), a novel text-only prompting framework that lever-"},{"angle":0,"pos":[105,1123,586,1123,586,1148,105,1148],"id":63,"text":"ages the rich semantics on graphs while addressing the chal-","score":0.99199998378754,"type":"line"},{"angle":0,"pos":[105,1145,586,1145,586,1169,105,1169],"id":64,"score":0.99400001764297,"text":"lenge of excessive prompt length. To reduce the informa-","type":"line"},{"angle":0,"pos":[105,1168,588,1168,588,1191,105,1191],"id":65,"score":0.99299997091293,"text":"tion loss incurred by early-stage encoding,DGP selectively","type":"line"},{"angle":0,"pos":[105,1190,586,1190,586,1214,105,1214],"id":66,"score":0.99099999666214,"type":"line","text":"preserves fine-grained text for the target node while sum-"},{"angle":0,"pos":[105,1211,588,1211,588,1236,105,1236],"id":67,"score":0.99199998378754,"text":"marizing neighbors retrieved from different metapaths into","type":"line"},{"angle":0,"pos":[105,1234,588,1234,588,1258,105,1258],"id":68,"score":0.98100000619888,"type":"line","text":"compact, coarse-grained texts. For textual features, we em-"},{"angle":0,"pos":[105,1255,588,1255,588,1279,105,1279],"id":69,"score":0.98100000619888,"type":"line","text":"ploy bi-level semantic summarization to reduce the prompt"},{"angle":0,"pos":[105,1276,588,1276,588,1301,105,1301],"id":70,"type":"line","score":0.98199999332428,"text":"length. For numerical features, we adopt precise numerical"},{"angle":0,"pos":[105,1298,586,1298,586,1323,105,1323],"id":71,"type":"line","score":0.98600000143051,"text":"summarization to retain key insights. As illustrated in Fig-"},{"angle":0,"pos":[105,1321,588,1321,588,1344,105,1344],"id":72,"score":0.99500000476837,"text":"ure 2,our approach achieves an impressive balance between","type":"line"},{"angle":0,"pos":[105,1343,586,1343,586,1367,105,1367],"id":73,"score":0.98600000143051,"type":"line","text":"token usage and performance. Compared to prior state-of-"},{"angle":0,"pos":[105,1364,588,1364,588,1389,105,1389],"id":74,"score":0.98100000619888,"type":"line","text":"the-art methods, DGP operates with a manageable prompt"},{"angle":0,"pos":[105,1388,588,1388,588,1411,105,1411],"id":75,"score":0.98600000143051,"text":"length while improving fraud detection performance by up","type":"line"},{"angle":0,"pos":[636,110,1118,110,1118,135,636,135],"id":76,"score":0.98500001430511,"type":"line","text":"to 6.8% (AUPRC), demonstrating the effectiveness of our"},{"angle":0,"pos":[636,133,1077,133,1077,156,636,156],"id":77,"text":"dual-granularity design with reasonable token budgets.","score":0.9879999756813,"type":"line"},{"angle":0,"pos":[656,156,1035,156,1035,179,656,179],"id":78,"type":"line","score":0.98500001430511,"text":"The key contribution of this work is three-fold:"},{"angle":0,"pos":[645,189,1118,189,1118,213,645,213],"id":79,"type":"line","score":0.98199999332428,"text":"·We propose DGP, a novel graph prompting framework"},{"angle":0,"pos":[661,210,1118,210,1118,235,661,235],"id":80,"text":"that integrates fine-grained textual details for target nodes","score":0.99800002574921,"type":"line"},{"angle":0,"pos":[662,234,1118,234,1118,257,662,257],"id":81,"type":"line","score":0.99599999189377,"text":"with coarse-grained semantic summaries for their neigh-"},{"angle":0,"pos":[662,255,1118,255,1118,278,662,278],"id":82,"text":"bors,thereby overcoming limitations faced by existing","score":0.99599999189377,"type":"line"},{"angle":0,"pos":[662,277,876,277,876,302,662,302],"id":83,"score":0.99500000476837,"text":"graph-to-prompt methods.","type":"line"},{"angle":0,"pos":[645,305,1118,305,1118,329,645,329],"id":84,"text":"·We introduce specialized summarization strategies for","score":0.99000000953674,"type":"line"},{"angle":0,"pos":[662,328,1118,328,1118,353,662,353],"id":85,"score":0.99199998378754,"type":"line","text":"compressing neighborhoods associated with textual and"},{"angle":0,"pos":[661,350,1118,350,1118,374,661,374],"id":86,"type":"line","score":0.99199998378754,"text":"numerical features into concise, semmantically meaningful"},{"angle":0,"pos":[660,372,968,370,968,396,661,398],"id":87,"score":0.99599999189377,"text":"prompts tailored for LLM processing.","type":"line"},{"angle":0,"pos":[645,401,1118,401,1118,425,645,425],"id":88,"type":"line","score":0.9879999756813,"text":"·Extensive experiments on public and industry datasets"},{"angle":0,"pos":[661,424,1118,424,1118,449,661,449],"id":89,"type":"line","score":0.99400001764297,"text":"demonstrate the superior empirical performance of DGP,"},{"angle":0,"pos":[662,446,1118,446,1118,470,662,470],"id":90,"score":0.98900002241135,"text":"achieving manageable prompt lengths while improving","type":"line"},{"angle":0,"pos":[661,467,1118,467,1118,492,661,492],"id":91,"type":"line","score":0.98500001430511,"text":"fraud detection performance by up to 6.8% in AUPRC"},{"angle":0,"pos":[661,490,988,490,988,515,661,515],"id":92,"score":0.9990000128746,"type":"line","text":"compared to state-of-the-art approaches."},{"angle":0,"pos":[784,537,968,537,968,562,784,562],"id":93,"text":"2 Related Work","score":0.99199998378754,"type":"line"},{"angle":0,"pos":[636,571,1108,571,1108,599,636,599],"id":94,"score":0.99099999666214,"type":"line","text":"2.1 Graph Neural Networks for Fraud Detection"},{"angle":0,"pos":[636,606,1118,606,1118,631,636,631],"id":95,"score":0.9879999756813,"text":"Graph neural networks (GNNs) have become the dominant","type":"line"},{"angle":0,"pos":[636,628,1118,628,1118,653,636,653],"id":96,"type":"line","score":0.99000000953674,"text":"approach for fraud detection by modeling relational pat-"},{"angle":0,"pos":[636,651,1118,651,1118,674,636,674],"id":97,"type":"line","score":0.98100000619888,"text":"terns in graphs (Akoglu, Tong, and Koutra 2015; Rayana"},{"angle":0,"pos":[636,673,1117,673,1117,696,636,696],"id":98,"score":0.98400002717972,"type":"line","text":"and Akoglu 2015; Duan et al. 2024; Li et al. 2024).Clas-"},{"angle":0,"pos":[636,693,1118,693,1118,718,636,718],"id":99,"score":0.98100000619888,"text":"sic models such as GCN (Kipf and Welling 2017) and","type":"line"},{"angle":0,"pos":[636,715,1118,715,1118,739,636,739],"id":100,"type":"line","score":0.97100001573563,"text":"GAT (Veličković et al. 2018) have inspired many variants"},{"angle":0,"pos":[636,738,1117,738,1117,763,636,763],"id":101,"score":0.98699998855591,"type":"line","text":"targeting specific challenges, including camouflage (CARE-"},{"angle":0,"pos":[636,760,1118,760,1118,783,636,783],"id":102,"type":"line","score":0.98900002241135,"text":"GNN (Dou et al. 2020)),heterophily (PMP (Zhuo et al."},{"angle":0,"pos":[636,779,1118,781,1118,807,636,806],"id":103,"score":0.97899997234344,"type":"line","text":"2024)), and limited supervision (ConsisGAD (Chen et al."},{"angle":0,"pos":[636,803,1117,803,1117,828,636,828],"id":104,"score":0.97600001096725,"text":"2024), barely-supervised learning (Yu, Liu, and Luo 2024)).","type":"line"},{"angle":0,"pos":[636,824,1118,824,1118,849,636,849],"id":105,"type":"line","score":0.9879999756813,"text":"However, most GNN-based approaches underutilize the"},{"angle":0,"pos":[636,848,1118,848,1118,872,636,872],"id":106,"score":0.99000000953674,"text":"fine-grained textual semantics widely available in real-world","type":"line"},{"angle":0,"pos":[634,869,1015,869,1015,894,634,894],"id":107,"score":0.99099999666214,"text":"graphs, which our method explicitly addresses.","type":"line"},{"angle":0,"pos":[636,913,982,913,982,940,636,940],"id":108,"type":"line","score":0.99000000953674,"text":"2.2 Integrating LLMs with Graphs"},{"angle":0,"pos":[636,948,1118,948,1118,973,636,973],"id":109,"score":0.98299998044968,"text":"Recent advances in integrating LLMs with graph data","type":"line"},{"angle":0,"pos":[636,970,1118,970,1118,995,636,995],"id":110,"text":"can be broadly classified into graph-enhanced LLMs and","score":0.99199998378754,"type":"line"},{"angle":0,"pos":[636,992,1118,992,1118,1016,636,1016],"id":111,"type":"line","score":0.99199998378754,"text":"LLM-enhanced GNNs. Graph-enhanced LLMs primarily"},{"angle":0,"pos":[636,1013,1118,1013,1118,1038,636,1038],"id":112,"type":"line","score":0.99299997091293,"text":"adopt graph-to-prompt strategies, which can be divided"},{"angle":0,"pos":[636,1035,1117,1035,1117,1060,636,1060],"id":113,"score":0.99199998378754,"text":"into encoding-based prompting and text-only prompting.","type":"line"},{"angle":0,"pos":[636,1058,1118,1058,1118,1083,636,1083],"id":114,"text":"Encoding-based prompting (Tang et al. 2024a,b) compresses","score":0.97500002384186,"type":"line"},{"angle":0,"pos":[636,1080,1117,1080,1117,1104,636,1104],"id":115,"type":"line","score":0.99099999666214,"text":"graph features for LLM input, potentially resulting in se-"},{"angle":0,"pos":[636,1101,1117,1101,1117,1126,636,1126],"id":116,"score":0.98299998044968,"type":"line","text":"mantic loss. Specifically, GraphGPT (Tang et al. 2024a)"},{"angle":0,"pos":[636,1123,1118,1123,1118,1148,636,1148],"id":117,"score":0.99000000953674,"text":"aligns LLMs with graph structural information via a dual-","type":"line"},{"angle":0,"pos":[636,1146,1117,1146,1117,1169,636,1169],"id":118,"type":"line","score":0.99199998378754,"text":"stage instruction-tuning paradigm and a graph-text align-"},{"angle":0,"pos":[636,1168,1118,1168,1118,1193,636,1193],"id":119,"score":0.9879999756813,"type":"line","text":"ment projector. HiGPT (Tang et al. 2024b) extends instruc-"},{"angle":0,"pos":[636,1190,1117,1190,1117,1214,636,1214],"id":120,"score":0.99599999189377,"type":"line","text":"tion tuning to heterogeneous graphs by introducing an in-"},{"angle":0,"pos":[636,1213,1118,1213,1118,1236,636,1236],"id":121,"text":"context heterogeneous-graph tokenizer and heterogeneity-","score":0.99599999189377,"type":"line"},{"angle":0,"pos":[636,1233,1118,1234,1118,1259,636,1258],"id":122,"text":"aware fine-tuning. In contrast, text-only prompting (Fatemi,","score":0.98500001430511,"type":"line"},{"angle":0,"pos":[636,1255,1118,1255,1118,1278,636,1278],"id":123,"type":"line","score":0.97799998521805,"text":"Halcrow, and Perozzi 2023; Ye et al. 2024; Zhu et al."},{"angle":0,"pos":[636,1276,1118,1276,1118,1301,636,1301],"id":124,"score":0.98500001430511,"text":"2025) concatenates the texts of neighboring nodes as in-","type":"line"},{"angle":0,"pos":[636,1298,1118,1298,1118,1323,636,1323],"id":125,"text":"put to LLMs,which may lead to excessively long prompts","score":0.99299997091293,"type":"line"},{"angle":0,"pos":[636,1319,1118,1321,1118,1346,636,1344],"id":126,"score":0.98100000619888,"type":"line","text":"and distract from crucial information. For example, Instruct-"},{"angle":0,"pos":[636,1341,1118,1343,1118,1369,636,1367],"id":127,"type":"line","score":0.97500002384186,"text":"GLM (Ye et al. 2024) frames graph tasks as natural-language"},{"angle":0,"pos":[636,1364,1118,1364,1118,1389,636,1389],"id":128,"type":"line","score":0.99099999666214,"text":"instructions for generative LLMs, enabling node classifica-"},{"angle":0,"pos":[636,1388,845,1388,845,1411,636,1411],"id":129,"score":0.99599999189377,"text":"tion on citation networks.","type":"line"}],"status":"Success","image_id":"99bf70b7b5b55e37.jpg","angle":0,"durations":1306.7105712891,"height":1584,"width":1224}],"version":"3.20.42","catalog":{"toc":[{"pos":[146,193,1075,193,1075,222,146,222],"paragraph_id":0,"page_id":1,"hierarchy":1,"pos_list":[[146,193,1075,193,1075,222,146,222]],"title":"DGP:A Dual-Granularity Prompting Framework for Fraud Detection with","sub_type":"text_title","level":1,"content":"DGP:A Dual-Granularity Prompting Framework for Fraud Detection with","pageNum":0},{"pos":[461,228,762,228,762,252,461,252],"paragraph_id":1,"page_id":1,"hierarchy":1,"pos_list":[[461,228,762,228,762,252,461,252]],"title":"Graph-Enhanced LLMs","sub_type":"text_title","level":1,"content":"Graph-Enhanced LLMs","pageNum":0},{"title":"Abstract","paragraph_id":5,"page_id":1,"hierarchy":2,"pos_list":[[308,438,383,438,383,450,308,450]],"pos":[308,438,383,438,383,450,308,450],"sub_type":"text_title","level":2,"content":"Abstract","pageNum":0},{"title":"1 Introduction","paragraph_id":7,"page_id":1,"hierarchy":2,"pos_list":[[261,1117,430,1117,430,1134,261,1134]],"pos":[261,1117,430,1117,430,1134,261,1134],"sub_type":"text_title","level":2,"content":"1 Introduction","pageNum":0},{"title":"(a) Fraudsters exhibit rich semantic patterns","paragraph_id":10,"page_id":1,"hierarchy":3,"pos_list":[[716,554,1036,554,1036,565,716,565]],"pos":[716,554,1036,554,1036,565,716,565],"sub_type":"image_title"},{"pos":[765,714,989,714,989,728,765,728],"paragraph_id":14,"page_id":1,"hierarchy":3,"pos_list":[[765,714,989,714,989,728,765,728]],"title":"(b) Encoding-based prompting","sub_type":"image_title"},{"pos":[787,879,966,879,966,895,787,895],"paragraph_id":19,"page_id":1,"hierarchy":3,"pos_list":[[787,879,966,879,966,895,787,895]],"title":"(c) Text-only prompting","sub_type":"image_title"},{"title":"Figure 1: Graph-to-prompt methods for fraud detection.","paragraph_id":20,"page_id":1,"hierarchy":3,"pos_list":[[652,918,1099,918,1099,936,652,936]],"pos":[652,918,1099,918,1099,936,652,936],"sub_type":"image_title"},{"title":"Figure 2: Fraud detection performance (↑) vs. token us-age per prompt (↓) across different methods and datasets. Our proposed method, DGP, achieves top performance with moderate token consumption, demonstrating a notable bal-ance between token usage and performance.","paragraph_id":2,"page_id":2,"hierarchy":3,"pos_list":[[104,287,586,287,586,390,104,390]],"pos":[104,287,586,287,586,390,104,390],"sub_type":"image_title"},{"title":"2 Related Work","paragraph_id":11,"page_id":2,"hierarchy":2,"pos_list":[[784,539,966,539,966,555,784,555]],"pos":[784,539,966,539,966,555,784,555],"sub_type":"text_title","level":2,"content":"2 Related Work","pageNum":1},{"title":"2.1 Graph Neural Networks for Fraud Detection","paragraph_id":15,"page_id":2,"hierarchy":3,"pos_list":[[637,575,1106,575,1106,594,637,594]],"pos":[637,575,1106,575,1106,594,637,594],"sub_type":"text_title","level":3,"content":"2.1 Graph Neural Networks for Fraud Detection","pageNum":1},{"title":"2.2 Integrating LLMs with Graphs","paragraph_id":17,"page_id":2,"hierarchy":3,"pos_list":[[637,917,980,917,980,935,637,935]],"pos":[637,917,980,917,980,935,637,935],"sub_type":"text_title","level":3,"content":"2.2 Integrating LLMs with Graphs","pageNum":1}]},"excel_base64":"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","image_process":[],"total_page_number":2}